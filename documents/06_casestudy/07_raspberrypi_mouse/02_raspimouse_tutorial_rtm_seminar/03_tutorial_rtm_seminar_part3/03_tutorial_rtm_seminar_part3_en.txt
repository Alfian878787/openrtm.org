// Title: Tutorial (RTM Seminar, Part 3)
#contents

このページではRaspberry PiマウスとLEGO Mindstorms EV3を連携したRTシステムの構築を行います。

Raspberry Piマウスをアクセスポイントとして、ノートPCとEV3をアクセスポイントに接続します。

※Raspberry Piマウスと同じ番号のEV3を使用するようにしてください。

#br

#ref(robomech2018_8.jpg,/ja/node/6552,70%,center)
#br


** EV3のデバイス
EV3 には以下のデバイスが付属しています。

|CENTER:200||c
| ''ジャイロセンサー'' &br; &ref(https://afrel.co.jp/cms/wp-content/uploads/2013/04/45505_GyroSensor.jpg); | 確度モード: 精度 +/- 3°&br; 角速度モード: 最大 440 deg/sec &br; サンプリングレート 1,000 Hz |
| ''カラーセンサー'' &br; &ref(https://afrel.co.jp/cms/wp-content/uploads/2013/04/45506_color.jpg); | 計測: 赤色光の反射光、 周囲の明るさ、色 &br; 検出カラー数: 8色 （無色、黒、青、緑、黄、赤、白、茶）&br; サンプリングレート	1,000 Hz &br; 距離 約1mm～18mm（アフレル調査値）|
| ''タッチセンサー'' &br; &ref(https://afrel.co.jp/cms/wp-content/uploads/2013/04/45507_TouchSensor.jpg); | オン (1), オフ (0) &br; スイッチ可動域: 約4mm |
| ''超音波センサー'' &br; &ref(https://afrel.co.jp/cms/wp-content/uploads/2013/04/45504_UltrasonicSensor.jpg); | 距離計測可能範囲: 3cmから250cm &br; 距離計測精度: +/- 1 cm &br; 前面電飾: 点灯：超音波発信中、 点滅：超音波観測中 |

|CENTER:200||c
| ''EV3 Lモーター'' &br; &ref(https://afrel.co.jp/cms/wp-content/uploads/2013/04/45502_LargeMotor.jpg); | フィードバック: 1°単位 &br; 回転数: 160から170RPM &br; 定格トルク: 0.21 N・m (30oz*in) &br; 停動トルク: 0.42 N・m (60oz*in) &br; 重さ: 76 g |
| ''EV3 Mモーター'' &br; &ref(https://afrel.co.jp/cms/wp-content/uploads/2013/04/45503_MediumMotor.jpg); | フィードバック 1°単位 &br; 回転数: 240から250RPM &br; 定格トルク: 0.08 N・m (11oz*in) &br; 停動トルク: 0.12 N・m (17oz*in) &br; 重さ: 36 g |


** EV3の組立て
まず、EV3本体を土台に装着します。

#br

#ref(robomech2018_12.jpg,/ja/node/6552,80%,center)
#br

次に25cmケーブルでEV3と左右のLモーターを接続します。

#br

#ref(https://afrel.co.jp/cms/wp-content/uploads/2013/04/45502_LargeMotor.jpg,100%,center)
CENTER:''Lモーター''
#br

| Lモーター右   | ポート C |25cmケーブル|
| Lモーター左   | ポート B |25cmケーブル|

#br

#ref(robomech2018_13.jpg,/ja/node/6552,100%,center)
#br

ケーブルに接続するポート、デバイス名は記載してあります。

他のデバイスを取り付ける場合は、[[チュートリアル(EV3)>/ja/node/6381#toc30]]を参考にしてください。

** EV3との接続
*** ノートPCとRaspberry Piの接続
[[第二部>/ja/node/6551]]の、実機での動作確認まで完了してください。
この時点でノートPCとアクセスポイントのRaspberry Piが接続されているはずです。



#br

#ref(robomech2018_9.jpg,/ja/node/6552,50%,center)
#br


** EV3の電源の入れ方/切り方

*** 電源の入れ方

中央のボタンを押せば電源が投入されます。

#br

#ref(ev3_on.jpg,/ja/node/6041,center,50%)
#br

*** 電源の切り方

EV3 の電源を切る場合は最初の画面で EV3 本体の左上の戻るボタンを押して「Power Off」を選択してください。

#br

#ref(ev3_off.jpg,/ja/node/6041,center,50%)
#br



#br

#ref(s_DSC01033.JPG,/ja/node/6041,center,50%)
#br

*** 再起動

再起動する場合は最初の画面で EV3 本体の左上の戻るボタンを押して「Reboot」を選択してください。

*** リセット

ev3dev の起動が途中で停止する場合には、中央ボタン、戻るボタン(左上)、左ボタンを同時押ししてください。画面が消えたら戻るボタンを離すと再起動します。


#br

#ref(ev3_reset.jpg,/ja/node/6041,center,50%)
#br


*** Raspberry PiとEV3の接続

EV3の電源を投入してください。

起動後にRaspberry Piに自動接続します。
自動接続できた場合は、EV3の画面左上にIPアドレスが表示されます。
IPアドレスは192.168.11.yyyが表示されます。


#br

#ref(tutorial_ev3_irex25.png,/ja/node/6384,50%,center)
#br



**** ネームサーバー、RTCの起動
EV3の画面上の操作でネームサーバーとRTCを起動します。

EV3 の操作画面から「File Browser」→「scripts」を選択してください。


ネームサーバー、RTCは''start_rtcs.sh''のスクリプトを実行することで起動します。

 ------------------------------
 192.168.11.yyy
 ------------------------------
         File Browser
 ------------------------------
 /home/robot/scripts
 ------------------------------
 ../
 Component/
 ・・
 [start_rtcs.sh                 ]
 ------------------------------


#br

#ref(tutorial_ev3_irex32.png,/ja/node/6384,center,50%)
#br



*** ネームサーバー追加
RTシステムエディタから、192.168.11.yyyのネームサーバーに接続してください。




#br

CENTER:&ref(tutorial_raspimouse0.png,50%,center);  &ref(tutorial_ev3_irex22.png,70%,center);
&br;
#br



この時点でRTシステムエディタのネームサービスビューにはlocalhost、192.168.11.1、192.168.11.yyyのネームサーバーが登録されています。
192.168.11.yyyのネームサーバーに登録されているRTCの名前は''EducatorVehicle1''となります。





#br

#ref(robomech2018_10.jpg,/ja/node/6552,center)
#br

- localhost
-- RobotController0
- 192.168.11.1
-- RaspberryPiMouseRTC0
-- OpenCVCamera0
-- artp0
- 192.168.11.yyy
-- EducatorVehicle1


** 動作確認

RaspberryPiMouseRTC0(192.168.11.1)とEducatorVehicle1(192.168.11.yyy)をシステムダイアグラム上で接続してください。
EducatorVehicle0の現在の速度出力をRaspberryPiMouseRTC0の目標速度入力に接続することで、EV3の動きにRaspberry Piマウスが追従するようになります。


#br

#ref(robomech2018_14.jpg,/ja/node/6552,center)
#br


RTCをアクティベートしてEducator Vehicleの車輪を転がすと、Raspberry Piマウスがそれに合わせて動作します。



#br

#ref(robomech2018_11.jpg,/ja/node/6552,100%,center)
#br


** 自由課題
これで実習は一通り終了ですが、時間が余っている場合は以下のような課題に挑戦してみてください。


*** EV3のタッチセンサのオンオフでRaspberry Piマウスを操作

EV3のタッチセンサーのオンオフでRaspberry Piマウスを前進後退させるRTシステムを作成します。


#br

#ref(https://afrel.co.jp/cms/wp-content/uploads/2013/04/45507_TouchSensor.jpg,100%,center)
CENTER:''タッチセンサー''
#br

**** タッチセンサー接続

EV3とタッチセンサーを35cmケーブルで接続してください。



| タッチセンサー右 | ポート 3 |35cmケーブル|
| タッチセンサー左 | ポート 1 |35cmケーブル|

**** RTCの作成

以下のような仕様のRTCを作成します。

|コンポーネント名称 | SampleTouchSensor |
|>|CENTER: InPort|
|ポート名|touch|
|型|TimedBooleanSeq|
|説明|タッチセンサーのオンオフ|
|>|CENTER: OutPort|
|ポート名|target_velocity|
|型|TimedVelocity2D|
|説明|目標速度|
|>|CENTER: Configuration|
|パラメーター名|speed|
|型|double|
|デフォルト値|0.2|
|説明| タッチセンサがオンの時の直進速度の設定 |

アクティビティでonExecuteを有効にしてください。

SampleTouchSensorのonExecute関数に以下のように記述します。


 RTC::ReturnCode_t SampleTouchSensor::onExecute(RTC::UniqueId ec_id)
 {
 	//新規データの確認
 	if (m_touchIn.isNew())
 	{
 		//データの読み込み
 		m_touchIn.read();
 		//配列の要素数が1以上かを確認
 		if (m_touch.data.length() == 2)
 		{
 			//0番目のデータがオンの場合は直進する指令を出力
 			//0番目のデータは右側のタッチセンサに対応
 			if (m_touch.data[0])
 			{
 				//目標速度を格納
 				m_target_velocity.data.vx = m_speed;
 				m_target_velocity.data.vy = 0;
 				m_target_velocity.data.va = 0;
 				setTimestamp(m_target_velocity);
 				//データ出力
 				m_target_velocityOut.write();
 			}
 			//1番目のデータがオンの場合は後退する指令を出力
 			//1番目のデータは左側のタッチセンサに対応
 			else if (m_touch.data[1])
 			{
 				//目標速度を格納
 				m_target_velocity.data.vx = -m_speed;
 				m_target_velocity.data.vy = 0;
 				m_target_velocity.data.va = 0;
 				setTimestamp(m_target_velocity);
 				//データ出力
 				m_target_velocityOut.write();
 			}
 			//オフの場合は停止する
 			else
 			{
 				//目標速度を格納
 				m_target_velocity.data.vx = 0;
 				m_target_velocity.data.vy = 0;
 				m_target_velocity.data.va = 0;
 				setTimestamp(m_target_velocity);
 				//データ出力
 				m_target_velocityOut.write();
 			}
 		}
 	}
   return RTC::RTC_OK;
 }

**** RTシステム作成

データポートを以下のように接続後、タッチセンサをオンオフするとRaspberry Piが前進後退します。

#br

#ref(robomech2018_15.jpg,/ja/node/6552,100%,center)
#br

*** ジョイスティックコンポーネントで2台同時に操作

以下GUIジョイスティックでRaspberry Piマウス、EV3を操作するRTシステムを作成します。

#br

#ref(robomech2018_18.jpg,/ja/node/6552,50%,center)
#br

**** ジョイスティックコンポーネント起動

ジョイスティックコンポーネントはOpenRTM-aist Python版のサンプルにあります(''TkJoyStickComp.py'')。
ジョイスティックコンポーネントは、Windows 8.1の場合は「スタート」>「アプリビュー(右下矢印)」>「OpenRTM-aist 1.2.0」>「Python_Examples」をクリックして、エクスプローラーで「TkJoyStickComp.bat」をダブルクリックして起動してください。

**** RTC作成

TkJoyStickComp.pyのアウトポートのデータ型は''TimedFloatSeq''型であるため、''TimedVelocity2D''型に変換するRTCを作成する必要があります。

以下のような仕様のRTCを作成してください。

|コンポーネント名称 | FloatSeqToVelocity |
|>|CENTER: InPort|
|ポート名|in|
|型|TimedFloatSeq|
|説明|変換前のデータ|
|>|CENTER: OutPort|
|ポート名|out|
|型|TimedVelocity2D|
|説明|変換後のデータ|
|>|CENTER: Configuration|
|パラメーター名|rotation_by_position|
|型|double|
|デフォルト値|-0.02|
|説明| ジョイスティックのX座標の位置に対する角速度の変化量 |
|>|CENTER: Configuration|
|パラメーター名|velocity_by_position|
|型|double|
|デフォルト値|0.002|
|説明| ジョイステックのY座標に対する速度の変化量 |

アクティビティはonExecuteをオンにしてください。

onExecute関数を以下のように編集してください。

 RTC::ReturnCode_t FloatSeqToVelocity::onExecute(RTC::UniqueId ec_id)
 {
 	//新規データの確認
 	if (m_inIn.isNew())
 	{
 		//データの読み込み
 		m_inIn.read();
 		//配列のデータ数確認
 		if (m_in.data.length() >= 2)
 		{
 			//目標速度格納
 			m_out.data.vx = m_in.data[1] * m_velocity_by_position;
 			m_out.data.vy = 0;
 			m_out.data.va = m_in.data[0] * m_rotation_by_position;
 			setTimestamp(m_out);
 			//目標速度出力
 			m_outOut.write();
 		}
 	}
   return RTC::RTC_OK;
 }

**** RTシステム作成

以下のようにデータポートを接続してください。

#br

#ref(robomech2018_16.jpg,/ja/node/6552,center)
#br


*** EV3をしゃべらせる

EducatorVehicleRTCの''sound''という名前のインポートに文字列(TimedString型)を入力すると、EV3が発声します。

**** RTC作成

以下のような仕様のRTCを作成してください。

|コンポーネント名称 | SpeechSample|
|>|CENTER: OutPort|
|ポート名|out|
|型|TimedString|
|説明|発話する文字列|

アクティビティはonExecuteをオンにしてください。

onExecute関数を以下のように編集してください。


 RTC::ReturnCode_t SpeechSample::onExecute(RTC::UniqueId ec_id)
 {
 	std::cout << "Please input: ";
 	std::string ret;
 	//文字入力
 	std::cin >> ret;
 	//データに格納
 	m_out.data = CORBA::string_dup(ret.c_str());
 	setTimestamp(m_out);
 	//データ出力
 	m_outOut.write();
 
   return RTC::RTC_OK;
 }



文字列(const char*)をデータポートで出力する際は''CORBA::string_dup関数''で文字列をコピーする必要があります。

 m_out.data= CORBA::string_dup("abc");


**** RTシステム作成

以下のようにデータポートを接続してください。

#br

#ref(robomech2018_17.jpg,/ja/node/6552,center)
#br

*** マーカーの追従

Raspberry Piマウスを起動すると、OpenCVCameraコンポーネントとarptコンポーネントが起動します。
OpenCVCameraコンポーネントは画像を取得するコンポーネント、artpコンポーネントは画像データからマーカの位置姿勢を計算して出力するコンポーネントです。

#br

#ref(robomech2018_19.jpg,/ja/node/6552,center)
#br

Raspberry Piマウスがマーカーに追従するRTシステムを作成します。

**** カメラの装着

まずはカメラをRaspberry Piマウスに装着します。

以下の土台部品をRaspberry Piマウスに取り付けていきます。

#br

#ref(robomech2018_23.jpg,/ja/node/6552,center)
#br

部品①をRaspberry Piマウスの上部に装着してください。
左から押し込むようにして取り付けます。

#br

#ref(s_DSC09198.JPG,/ja/node/6552,center)
#br

#br

この時、左側の突起がプレートを挟むように取り付けてください。

#br

#ref(robomech2018_22.jpg,/ja/node/6552,center)
#br


部品②を部品①の左側に上から差し込んでください。

#br

#ref(s_DSC09201.JPG,/ja/node/6552,center)
#br

#br


#br

#ref(robomech2018_25.jpg,/ja/node/6552,center)
#br


部品③を左側から部品②に差し込んでください。



#br

#ref(robomech2018_24.jpg,/ja/node/6552,center)
#br



最後にカメラを搭載して、USBケーブルをRaspberry Piに差し込んだら完成です。

#br

#ref(s_DSC01096.JPG,/ja/node/6552,center)
#br

#br

#br

#ref(s_DSC01098.JPG,/ja/node/6552,center)
#br

#br


**** RTC作成

以下の仕様でRTCを作成してください。



|コンポーネント名称 | testARToolKit |
|>|CENTER: InPort|
|ポート名|marker_pos|
|型|TimedPose3D|
|説明|マーカーの位置|
|>|CENTER: OutPort|
|ポート名|target_vel|
|型|TimedVelocity2D|
|説明|ロボットの目標速度|
|>|CENTER: Configuration|
|パラメーター名|x_distance|
|型|double|
|デフォルト値|0.5|
|説明| マーカーまでの目標距離(X軸) |
|>|CENTER: Configuration|
|パラメーター名|y_distance|
|型|double|
|デフォルト値|0|
|説明| マーカーまでの目標距離(Y軸) |
|>|CENTER: Configuration|
|パラメーター名|x_speed|
|型|double|
|デフォルト値|0.1|
|説明| X軸方向移動速度 |
|>|CENTER: Configuration|
|パラメーター名|r_speed|
|型|double|
|デフォルト値|0.2|
|説明| 回転方向移動速度 |
|>|CENTER: Configuration|
|パラメーター名|error_range_x|
|型|double|
|デフォルト値|0.1|
|説明| X軸方向目標距離の許容範囲 |
|>|CENTER: Configuration|
|パラメーター名|error_range_y|
|型|double|
|デフォルト値|0.05|
|説明| Y軸方向目標距離の許容範囲 |


アクティビティはonExecuteをONにしてください。

onExecuteを以下のように編集してください。



 RTC::ReturnCode_t testARToolKit::onExecute(RTC::UniqueId ec_id)
 {
 	//新規データの確認
 	if (m_marker_posIn.isNew())
 	{
 		m_target_vel.data.vx = 0;
 		m_target_vel.data.vy = 0;
 		m_target_vel.data.va = 0;
 
 		//データの読み込み
 		m_marker_posIn.read();
 		//マーカーの位置(X軸)が目標距離(X軸)よりも大きい場合
 		if (m_marker_pos.data.position.x > m_x_distance + m_error_range_x/2.0)
 		{
 			m_target_vel.data.vx = m_x_speed;
 		}
 		//マーカーの位置(X軸)が目標距離(X軸)よりも小さい場合
 		else if (m_marker_pos.data.position.x < m_x_distance - m_error_range_x/2.0)
 		{
 			m_target_vel.data.vx = -m_x_speed;
 		}
 		//マーカーの位置(Y軸)が目標距離(Y軸)よりも大きい場合
 		else if (m_marker_pos.data.position.y > m_y_distance + m_error_range_y/2.0)
 		{
 			m_target_vel.data.va = m_r_speed;
 		}
 		//マーカーの位置(Y軸)が目標距離(Y軸)よりも小さい場合
 		else if (m_marker_pos.data.position.y < m_y_distance - m_error_range_y/2.0)
 		{
 			m_target_vel.data.va = -m_r_speed;
 		}
 		setTimestamp(m_target_vel);
 		//データ書き込み
 		m_target_velOut.write();
 	}
   return RTC::RTC_OK;
 }

**** RTシステム作成

データポートを以下のように接続してください。

#br

#ref(robomech2018_20.jpg,/ja/node/6552,center)
#br

RTCをアクティベートしてカメラの前でマーカーを動かして、Raspberry Piマウスが移動するかを確認してください。

